# -*- coding: utf-8 -*-
"""us_hate_crimes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cbm3VtAqy2HvMSoL1g-cPWIPZK34Btg8
"""

import pandas as pd
import numpy as np

crimes_df = pd.read_csv('hate_crime.csv')

crimes_df

crimes_df.columns

len(crimes_df)

crimes_df['DATA_YEAR'].unique()

crimes_df['STATE_ABBR'].unique()

crimes_df['STATE_NAME'].unique()

#take out federal and Guam
crimes_df = crimes_df[crimes_df['STATE_ABBR'] != 'FS']
crimes_df = crimes_df[crimes_df['STATE_ABBR'] != 'GM']

#Check that df only consists of 50 states and DC
len(crimes_df['STATE_ABBR'].unique())

crimes_df['BIAS_DESC'].unique()
#Found "Anti-Asian", "Anti-Female"

crimes_df = crimes_df[crimes_df['BIAS_DESC'].str.contains('Anti-Asian')]

len(crimes_df)
#6462 hate crimes against Asians

sum(crimes_df['BIAS_DESC'].str.contains('Anti-Female'))
#5 anti-asian, anti-female crimes

crimes_df['VICTIM_TYPES'].unique()

anti_asian_df = crimes_df.groupby('DATA_YEAR', as_index = False).agg({'INCIDENT_ID': 'count'})

#Anti-Asian crimes per year where victims are an individual, a business/financial institution, a government entity, a religious organization, or society/public as a whole
anti_asian_df

"""**From 2019 to 2020, there was a 68% increase in anti-Asian hate crimes. In the FBI's Hate Crime Statistics Program, victims are an individual, a business/financial institution, a government entity, a religious organization, or society/public as a whole.**"""

anti_asianfemale_df = crimes_df[crimes_df['BIAS_DESC'].str.contains('Anti-Female')]

anti_asianfemale_df.groupby('DATA_YEAR', as_index = False).agg({'INCIDENT_ID': 'count'})

"""**While we need more data on attacks against Asian females, the data indicates that there was a 200% increase in attacks directed toward this demographic.**"""

crimes_df

states_2019_df = crimes_df[crimes_df['DATA_YEAR'] == 2019].groupby('STATE_NAME').agg({'INCIDENT_ID': 'count'})
states_2020_df = crimes_df[crimes_df['DATA_YEAR'] == 2020].groupby('STATE_NAME').agg({'INCIDENT_ID': 'count'})

states_2020_df.to_csv('states2020.csv', index = True)
!cp states2020.csv "drive/My Drive/"

states_2020_2019_df = states_2019_df.merge(states_2020_df, on = "STATE_NAME").rename(columns = {"INCIDENT_ID_x": "Anti-Asian crimes 2019", "INCIDENT_ID_y": "Anti-Asian crimes 2020"})

states_2020_2019_df['Percent increase between 2020 and 2019'] = ((states_2020_2019_df['Anti-Asian crimes 2020'] - states_2020_2019_df['Anti-Asian crimes 2019']) / states_2020_2019_df['Anti-Asian crimes 2019'])*100

states_2020_2019_df.sort_values(by = ['Percent increase between 2020 and 2019'], ascending = False, inplace = True)

states_2020_2019_df

from google.colab import drive
drive.mount('drive')

states_2020_2019_df.to_csv('states.csv', index = True)
!cp states.csv "drive/My Drive/"

states_2020_2019_df[states_2020_2019_df['Percent increase between 2020 and 2019'] > 100]

"""**From 2019 to 2020, Minnesota and New York saw the greatest increase in anti-Asian crimes at 800% and 400%, respectively.**"""

crimes_df['LOCATION_NAME'].unique()

locations_2019_df = crimes_df[crimes_df['DATA_YEAR'] == 2019].groupby('LOCATION_NAME').agg({'INCIDENT_ID':'count'})
locations_2020_df = crimes_df[crimes_df['DATA_YEAR'] == 2020].groupby('LOCATION_NAME').agg({'INCIDENT_ID':'count'})

locations_2020_2019_df = locations_2019_df.merge(locations_2020_df, on = "LOCATION_NAME").rename(columns = {"INCIDENT_ID_x": "Anti-Asian crime location 2019", "INCIDENT_ID_y": "Anti-Asian crime location 2020"})

locations_2020_2019_df['Percent increase between 2020 and 2019'] = ((locations_2020_2019_df['Anti-Asian crime location 2020'] - locations_2020_2019_df['Anti-Asian crime location 2019']) / locations_2020_2019_df['Anti-Asian crime location 2019'])*100

locations_2020_2019_df.sort_values(by = ['Percent increase between 2020 and 2019'], ascending = False, inplace = True)

locations_2020_2019_df

locations_2020_2019_df[locations_2020_2019_df['Percent increase between 2020 and 2019'] > 100]

"""**From 2019 to 2020, there was a 550% and 500% increase in anti-Asian attacks at conveience stores and grocery/supermarkets, respectively.**"""

adult_juv_2019_df = crimes_df[crimes_df['DATA_YEAR'] == 2019].dropna(subset = ['ADULT_VICTIM_COUNT', 'JUVENILE_VICTIM_COUNT'])
adult_juv_2020_df = crimes_df[crimes_df['DATA_YEAR'] == 2020].dropna(subset = ['ADULT_VICTIM_COUNT', 'JUVENILE_VICTIM_COUNT'])

adult_2019 = sum(adult_juv_2019_df['ADULT_VICTIM_COUNT'])
adult_2020 = sum(adult_juv_2020_df['ADULT_VICTIM_COUNT'])

print("Number of Asian adult victims (18 or older) in 2019: ", adult_2019)
print("Number of Asian adult victims (18 or older) in 2020: ", adult_2020)
print("Percent increase in Asian adult victims: ", ((adult_2020 - adult_2019)/adult_2019)*100)

juv_2019 = sum(adult_juv_2019_df['JUVENILE_VICTIM_COUNT'])
juv_2020 = sum(adult_juv_2020_df['JUVENILE_VICTIM_COUNT'])

print("Number of Asian juvenile victims (under 18) in 2019: ", juv_2019)
print("Number of Asian juvenile victims (under 18) in 2020: ", juv_2020)
print("Percent increase in Asian juvenile (under 18) victims: ", ((juv_2020 - juv_2019)/juv_2019)*100)

"""**From 2019 to 2020, hate crimes targeting Asian adults (18 or older) jumped nearly 40% while those targeting Asian juveniles (under 18) increased 20%.**"""